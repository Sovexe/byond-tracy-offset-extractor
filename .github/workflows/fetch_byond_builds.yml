name: Fetch BYOND Builds

on:
  schedule:
    # run every hour
    - cron: "0 */1 * * *"
  workflow_dispatch: {}

permissions:
  contents: read

jobs:
  fetch_byond_builds:
    runs-on: ubuntu-latest
    env:
      PAGES_BASE: https://sovexe.github.io/byond-tracy-offset-extractor
      BUILDS_BASE: https://spacestation13.github.io/byond-builds
      MIN_MAJOR: "515"
      CHUNK_SIZE: "15"
    outputs:
      chunks: ${{ steps.prepare_chunks.outputs.chunks }}
      count: ${{ steps.prepare_chunks.outputs.count }}
    steps:
      - name: Tools
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq curl

      - name: Fetch our index.json (may be empty on first run)
        run: |
          set -euo pipefail
          curl -fsS "$PAGES_BASE/index.json" -o ours.json || echo '{}' > ours.json

      - name: Determine majors [515..latest]
        id: majors
        run: |
          set -euo pipefail
          UPSTREAM_VER="$(curl -fsS "$BUILDS_BASE/version.txt" | tr -d '\r\n')"
          LATEST_MAJOR="${UPSTREAM_VER%%.*}"
          seq "$MIN_MAJOR" "$LATEST_MAJOR" > majors.txt
          echo "Upstream latest: $UPSTREAM_VER"
          echo "Majors: $(tr '\n' ' ' < majors.txt)"

      - name: Crawl upstream versions (keep if ≥1 ZIP exists)
        run: |
          set -euo pipefail

          have_any_zip() {
            local major="$1" ver="$2"
            local win="$BUILDS_BASE/${major}/${ver}_byond.zip"
            local lin="$BUILDS_BASE/${major}/${ver}_byond_linux.zip"
            curl -fsI "$win" >/dev/null 2>&1 && return 0
            curl -fsI "$lin" >/dev/null 2>&1 && return 0
            return 1
          }

          : > upstream.sorted.txt
          while read -r MAJOR; do
            HTML="$(curl -fsS "$BUILDS_BASE/$MAJOR/" || true)"
            [ -z "$HTML" ] && continue
            printf '%s\n' "$HTML" \
              | grep -oE "$MAJOR\.[0-9]{4}" \
              | sort -u \
              | while read -r VER; do
                  have_any_zip "$MAJOR" "$VER" && echo "$VER"
                done
          done < majors.txt | sort -u > upstream.sorted.txt

          echo "Found upstream versions: $(wc -l < upstream.sorted.txt)"

      - name: Compute missing (upstream - ours)
        run: |
          set -euo pipefail
          jq -r '.versions // [] | .[]' ours.json 2>/dev/null | sort -u > ours.versions.txt || true
          cp upstream.sorted.txt upstream.versions.txt
          comm -13 ours.versions.txt upstream.versions.txt > missing.txt || true
          if [ -s missing.txt ]; then
            jq -R -s -c 'split("\n")[:-1]' missing.txt > missing.json
          else
            echo '[]' > missing.json
          fi
          echo "Missing count: $(jq 'length' missing.json)"

      - name: Prepare chunks of ${{ env.CHUNK_SIZE }}
        id: prepare_chunks
        run: |
          set -euo pipefail
          # chunks([]) => []
          CHUNKS="$(jq -c --argjson n "${CHUNK_SIZE}" '
            def chunks($n):
              if length==0 then []
              else [ range(0; length; $n) as $i | .[$i:($i+$n)] ]
              end;
            chunks($n)
          ' missing.json)"
          COUNT="$(jq 'length' missing.json)"
          {
            echo 'chunks<<EOF'
            echo "$CHUNKS"
            echo EOF
          } >> "$GITHUB_OUTPUT"
          {
            echo 'count<<EOF'
            echo "$COUNT"
            echo EOF
          } >> "$GITHUB_OUTPUT"

  # Run the extractor per chunk, but DO NOT publish here.
  extract_chunks:
    needs: fetch_byond_builds
    if: ${{ fromJson(needs.fetch_byond_builds.outputs.count) > 0 }}
    permissions:
      contents: read
    strategy:
      matrix:
        chunk: ${{ fromJson(needs.fetch_byond_builds.outputs.chunks) }}
      # parallel extract is fine; these jobs only upload site fragments
      max-parallel: 3
    uses: ./.github/workflows/extract_sigs.yml
    with:
      versions: ${{ toJson(matrix.chunk) }}
      publish: false

  # Single publish job at the very end
  publish_pages:
    needs: [fetch_byond_builds, extract_chunks]
    if: ${{ fromJson(needs.fetch_byond_builds.outputs.count) > 0 }}
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    environment:
      name: github-pages
    steps:
      - name: Download ALL fragments
        uses: actions/download-artifact@v4
        with:
          pattern: site-fragments-*
          merge-multiple: true
          path: fragments

      - name: Build static site files
        run: |
          set -euo pipefail
          mkdir -p public

          # Per-version/per-platform → public/v/<version>/<platform>.json
          find fragments -name '*.json' -print | sort | while read -r f; do
            base=$(basename "$f" .json)
            plat=${base%%-*}
            ver=${base#*-}
            mkdir -p "public/v/$ver"
            jq -c '.' "$f" > "public/v/$ver/$plat.json"
          done

          # data.json = flattened + sorted
          if ls public/v/*/*.json >/dev/null 2>&1; then
            jq -s '[ .[] ]' public/v/*/*.json \
              | jq 'sort_by(.version | split(".") | map(tonumber)) | sort_by(.platform)' \
              > public/data.json
          else
            echo '[]' > public/data.json
          fi

          # index.json (versions + latest per-platform)
          jq -r '.[].version' public/data.json \
            | sort -t. -k1,1n -k2,2n \
            | uniq > versions.txt || true

          latest_linux=$(jq -r '
            [.[] | select(.platform=="linux")]
            | (max_by(.version | split(".") | map(tonumber)) // empty)
            | if . == null then "" else .version end
          ' public/data.json)
          latest_windows=$(jq -r '
            [.[] | select(.platform=="windows")]
            | (max_by(.version | split(".") | map(tonumber)) // empty)
            | if . == null then "" else .version end
          ' public/data.json)

          jq -n --argjson versions "$(jq -R -s 'split("\n")[:-1]' versions.txt 2>/dev/null || echo '[]')" \
                --arg linux "$latest_linux" --arg windows "$latest_windows" \
            '{schema:1, versions:$versions, latest:{linux:$linux, windows:$windows}}' \
            > public/index.json

          # latest aliases
          if [ -n "$latest_linux" ] && [ -f "public/v/$latest_linux/linux.json" ]; then
            jq -c '.' "public/v/$latest_linux/linux.json" > public/latest-linux.json
          fi
          if [ -n "$latest_windows" ] && [ -f "public/v/$latest_windows/windows.json" ]; then
            jq -c '.' "public/v/$latest_windows/windows.json" > public/latest-windows.json
          fi
          if [ -f public/latest-linux.json ]; then
            cp public/latest-linux.json public/latest.json
          elif [ -f public/latest-windows.json ]; then
            cp public/latest-windows.json public/latest.json
          else
            echo '{}' > public/latest.json
          fi

      - name: Copy site assets (index.html etc.)
        run: |
          mkdir -p public
          cp -R pages/* public/ || true

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy to GitHub Pages
        id: deploy
        uses: actions/deploy-pages@v4
