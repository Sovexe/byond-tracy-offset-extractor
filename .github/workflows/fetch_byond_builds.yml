name: Fetch BYOND Builds

on:
  schedule:
    # run every hour
    - cron: "0 */1 * * *"
  workflow_dispatch: {}

permissions:
  contents: read

jobs:
  fetch_byond_builds:
    runs-on: ubuntu-latest
    env:
      PAGES_BASE: https://sovexe.github.io/byond-tracy-offset-extractor
      BUILDS_BASE: https://spacestation13.github.io/byond-builds
      MIN_MAJOR: "515"
      CHUNK_SIZE: "15"
    outputs:
      chunks: ${{ steps.prepare_chunks.outputs.chunks }}
      count: ${{ steps.prepare_chunks.outputs.count }}
    steps:
      - name: Tools
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq curl

      - name: Fetch our index.json (may be empty on first run)
        run: |
          set -euo pipefail
          curl -fsS "$PAGES_BASE/index.json" -o ours.json || echo '{}' > ours.json

      - name: Determine majors [515..latest]
        id: majors
        run: |
          set -euo pipefail
          UPSTREAM_VER="$(curl -fsS "$BUILDS_BASE/version.txt" | tr -d '\r\n')"
          LATEST_MAJOR="${UPSTREAM_VER%%.*}"
          seq "$MIN_MAJOR" "$LATEST_MAJOR" > majors.txt
          echo "Upstream latest: $UPSTREAM_VER"
          echo "Majors: $(tr '\n' ' ' < majors.txt)"

      - name: Crawl upstream versions (keep if â‰¥1 ZIP exists)
        run: |
          set -euo pipefail

          have_any_zip() {
            local major="$1" ver="$2"
            local win="$BUILDS_BASE/${major}/${ver}_byond.zip"
            local lin="$BUILDS_BASE/${major}/${ver}_byond_linux.zip"
            curl -fsI "$win" >/dev/null 2>&1 && return 0
            curl -fsI "$lin" >/dev/null 2>&1 && return 0
            return 1
          }

          : > upstream.txt
          while read -r MAJOR; do
            HTML="$(curl -fsS "$BUILDS_BASE/$MAJOR/" || true)"
            [ -z "$HTML" ] && continue
            printf '%s\n' "$HTML" \
              | grep -oE "$MAJOR\.[0-9]{4}" \
              | sort -u \
              | while read -r VER; do
                  if have_any_zip "$MAJOR" "$VER"; then
                    echo "$VER"
                  fi
                done
          done < majors.txt | sort -u > upstream.sorted.txt

          echo "Found upstream versions: $(wc -l < upstream.sorted.txt)"

      - name: Compute missing (upstream - ours)
        run: |
          set -euo pipefail
          jq -r '.versions // [] | .[]' ours.json 2>/dev/null | sort -u > ours.versions.txt || true
          cp upstream.sorted.txt upstream.versions.txt
          comm -13 ours.versions.txt upstream.versions.txt > missing.txt || true
          if [ -s missing.txt ]; then
            jq -R -s -c 'split("\n")[:-1]' missing.txt > missing.json
          else
            echo '[]' > missing.json
          fi
          echo "Missing count: $(jq 'length' missing.json)"

      - name: Prepare chunks of ${{ env.CHUNK_SIZE }}
        id: prepare_chunks
        run: |
          set -euo pipefail
          # chunks([]) => []
          CHUNKS="$(jq -c --argjson n "${CHUNK_SIZE}" '
            def chunks($n):
              if length==0 then []
              else [ range(0; length; $n) as $i | .[$i:($i+$n)] ]
              end;
            chunks($n)
          ' missing.json)"
          COUNT="$(jq 'length' missing.json)"
          {
            echo 'chunks<<EOF'
            echo "$CHUNKS"
            echo EOF
          } >> "$GITHUB_OUTPUT"
          {
            echo 'count<<EOF'
            echo "$COUNT"
            echo EOF
          } >> "$GITHUB_OUTPUT"

  extract_chunks:
    needs: fetch_byond_builds
    if: ${{ fromJson(needs.fetch_byond_builds.outputs.count) > 0 }}
    permissions:
      contents: read
      pages: write
      id-token: write
    strategy:
      matrix:
        chunk: ${{ fromJson(needs.fetch_byond_builds.outputs.chunks) }}
      max-parallel: 1
    uses: ./.github/workflows/extract_sigs.yml
    with:
      versions: ${{ toJson(matrix.chunk) }}
